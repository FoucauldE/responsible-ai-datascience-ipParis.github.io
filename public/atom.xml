<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bloggin on Responsible AI</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Bloggin on Responsible AI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 16:37:43 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/atom.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>XAI_transformers</title>
      <link>http://localhost:1313/posts/xai_transformers/</link>
      <pubDate>Fri, 28 Mar 2025 16:37:43 +0100</pubDate>
      <guid>http://localhost:1313/posts/xai_transformers/</guid>
      <description>&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;fr&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;   &lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;   &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;   &lt;title&gt;XAI for Transformers&lt;/title&gt;&#xD;&#xA;   &lt;style&gt;&#xD;&#xA;      body {&#xD;&#xA;         font-family: Arial, sans-serif;&#xD;&#xA;         line-height: 1.6;&#xD;&#xA;         margin: 40px;&#xD;&#xA;         background-color: #fff;&#xD;&#xA;         color: #111;&#xD;&#xA;      }&#xD;&#xA;      h1 {&#xD;&#xA;         font-size: 28px;&#xD;&#xA;         text-align: center;&#xD;&#xA;         margin-bottom: 5px;&#xD;&#xA;      }&#xD;&#xA;      .author-section {&#xD;&#xA;         display: flex;&#xD;&#xA;         gap: 20px;&#xD;&#xA;         margin-top: 20px;&#xD;&#xA;         margin-bottom: 20px;&#xD;&#xA;      }&#xD;&#xA;      .author-box {&#xD;&#xA;         display: flex;&#xD;&#xA;         align-items: center;&#xD;&#xA;      }&#xD;&#xA;      .author-box img {&#xD;&#xA;         width: 40px;&#xD;&#xA;         height: 40px;&#xD;&#xA;         border-radius: 50%;&#xD;&#xA;         margin-right: 10px;&#xD;&#xA;      }&#xD;&#xA;      .toc {&#xD;&#xA;         background-color: #f0f0f0;&#xD;&#xA;         padding: 15px;&#xD;&#xA;         border-radius: 8px;&#xD;&#xA;         margin-top: 30px;&#xD;&#xA;         margin-bottom: 30px;&#xD;&#xA;      }&#xD;&#xA;      .toc ul {&#xD;&#xA;         padding-left: 20px;&#xD;&#xA;         margin: 0;&#xD;&#xA;      }&#xD;&#xA;      .toc li {&#xD;&#xA;         margin-bottom: 6px;&#xD;&#xA;      }&#xD;&#xA;      blockquote {&#xD;&#xA;         font-style: italic;&#xD;&#xA;         color: #555;&#xD;&#xA;         border-left: 4px solid #ccc;&#xD;&#xA;         padding-left: 15px;&#xD;&#xA;         margin: 20px 0;&#xD;&#xA;      }&#xD;&#xA;      img.centered {&#xD;&#xA;         display: block;&#xD;&#xA;         margin: 20px auto;&#xD;&#xA;         max-width: 60%;&#xD;&#xA;      }&#xD;&#xA;      h3, h4 {&#xD;&#xA;         margin-top: 30px;&#xD;&#xA;      }&#xD;&#xA;   &lt;/style&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;body&gt;&#xD;&#xA;&lt;h1&gt;XAI for Transformers: Better explanations through conservative propagation&lt;/h1&gt;&#xD;&#xA;&lt;p style=&#34;text-align:center;&#34;&gt;Published March 28, 2025&lt;/p&gt;</description>
    </item>
    <item>
      <title>Axiomatic Explanations for Visual Search, Retrieval and Similarity Learning</title>
      <link>http://localhost:1313/posts/axiomatic_explanations/</link>
      <pubDate>Thu, 28 Mar 2024 05:58:39 +0100</pubDate>
      <guid>http://localhost:1313/posts/axiomatic_explanations/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;en&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;&lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;title&gt;Styled Table&lt;/title&gt;&#xD;&#xA;&lt;style&gt;&#xD;&#xA;    table {&#xD;&#xA;        border-collapse: collapse;&#xD;&#xA;        width: 100%;&#xD;&#xA;    }&#xD;&#xA;    th, td {&#xD;&#xA;        padding: 8px;&#xD;&#xA;        text-align: center;&#xD;&#xA;        border-bottom: 1px solid #ddd;&#xD;&#xA;    }&#xD;&#xA;    th {&#xD;&#xA;        background-color: #f2f2f2;&#xD;&#xA;    }&#xD;&#xA;    tr:hover {&#xD;&#xA;        background-color: #f5f5f5;&#xD;&#xA;    }&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;/html&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;AXIOMATIC EXPlanATIONS FOR VISUAL SEARCh, RETRIEVAL, AND SIMILARITY LEARNING &lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 13px;&#34;&gt;Authors:Mark Hamilton ${ }^{1,2}$, Scott Lundberg ${ }^{2}$, Stephanie Fu ${ }^{1}$, Lei Zhang ${ }^{2}$, William T. Freeman ${ }^{1,3}$&lt;br&gt;${ }^{1}$ MIT, ${ }^{2}$ Microsoft, ${ }^{3}$ Google&lt;br&gt;markth@mit.edu&#xD;&#xA;&lt;br/&gt;&#xD;&#xA;**Authors of the blogpost**: Yassine Beniguemim and Noureddine BOULLAM.&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Exploring Visual Search Algorithm Explanations&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.1&#34;&gt;First-Order Explanations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.2&#34;&gt;Unifying First-Order Search Interpretation Techniques&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.3&#34;&gt;Second-Order Explanations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.4&#34;&gt;A Fast Shapley-Taylor Approximation Kernel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.5&#34;&gt;Second-Order Search Activation Maps&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Implementing Second-Order Explanations in Practice&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0.0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;Visual search, recommendation, and contrastive similarity learning are pivotal technologies shaping user experiences in the digital age. However, the complexity of modern model architectures often obscures their inner workings, making them challenging to interpret. In our blog, we delve into a groundbreaking paper titled &amp;ldquo;AXIOMATIC EXPLANATIONS FOR VISUAL SEARCH, RETRIEVAL, AND SIMILARITY LEARNING&amp;rdquo; authored by Mark Hamilton et al. This paper introduces a novel framework grounded in the theory of fair credit assignment, providing axiomatic solutions that generalize existing explanation techniques and address fairness concerns in recommendation systems. Through our exploration, we aim to demystify the complexities of visual search algorithms, offering readers insights into their operation and implications for various domains.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Privacy Amplification by Decentralization</title>
      <link>http://localhost:1313/posts/privacy-amplification/</link>
      <pubDate>Wed, 27 Mar 2024 12:05:50 +0100</pubDate>
      <guid>http://localhost:1313/posts/privacy-amplification/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Privacy Amplification by Decentralization&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Sarah ABBANA BENNANI &lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction - the challenge of data privacy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Theoretical Aspects on Differential Privacy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;First Case: walk on a ring&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Generalisation: walk on a complete graph&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Perspectives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br /&gt;&#xD;&#xA;&lt;p&gt;This is a blogpost about the paper  Privacy Amplification by Decentralization, published by E. Cyffers et al. in 2022 and available &lt;a href=&#34;https://proceedings.mlr.press/v151/cyffers22a/cyffers22a.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;section-1&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Introduction - the challenge of data privacy&lt;/h1&gt;&lt;/h1&gt;&#xA;&lt;p&gt;In recent years, the concept of privacy has gained significant attention due to the proliferation of data collection practices and the need to safeguard individuals&amp;rsquo; personal information. &lt;br&gt;&#xA;There has been a notable shift towards implementing regulations to govern the gathering of data from individuals, underscoring the pressing demand for privacy measures that are not only effective and robust against potential attacks but also transparent and firmly grounded in logic and mathematics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Robust or Fair</title>
      <link>http://localhost:1313/posts/robust-or-fair/</link>
      <pubDate>Wed, 27 Mar 2024 11:37:03 +0100</pubDate>
      <guid>http://localhost:1313/posts/robust-or-fair/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;To be Robust or to be Fair: Towards Fairness in Adversarial Training&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Authors: Maryem Hajji &amp; Cément Teulier&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Initial Analysis&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2.1&#34;&gt;Previous Studies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2.2&#34;&gt;Theoretical Demonstration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Model&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3.1&#34;&gt;Fairness Requirements&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3.2&#34;&gt;Practical Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Experimentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;This blog post retraces the study conducted in the &lt;a href=&#34;http://proceedings.mlr.press/v139/xu21b.html&#34;&gt;paper&lt;/a&gt; &amp;ldquo;To be Robust or to be Fair: Towards Fairness in Adversarial Training&amp;rdquo; and written by Han Xu, Xiaorui Liu, Yaxin Li, Yaxin Li, Anil K. Jain and Jiliang Tang.&lt;/p&gt;</description>
    </item>
    <item>
      <title>XCM, an explainable CNN for MTS classficiation</title>
      <link>http://localhost:1313/posts/xcm/</link>
      <pubDate>Tue, 26 Mar 2024 00:55:40 +0100</pubDate>
      <guid>http://localhost:1313/posts/xcm/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification&lt;/h1&gt;&#xD;&#xA;&lt;h3 style=&#34;font-size: 24px;&#34;&gt;Authors : Nicolas SAINT &amp; Matthis Guérin&lt;/h3&gt;&#xD;&#xA;&lt;h4 style=&#34;font-size: 22px;&#34;&gt;Table of Contents&#xD;&#xA;&lt;/h4&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#2-related-work&#34;&gt;2. Related Work&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#3-xcm&#34;&gt;3. XCM&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#4-evaluation&#34;&gt;4. Evaluation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#5-results&#34;&gt;5. Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#6-implementation&#34;&gt;6. Implementation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#7-conclusion&#34;&gt;7. Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the article &amp;ldquo;XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification&amp;rdquo; published by Kevin Fauvel et al. in 2021 and available &lt;a href=&#34;https://www.mdpi.com/2227-7390/9/23/3137&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RobustAI_RegMixup</title>
      <link>http://localhost:1313/posts/robustai_regmixup/</link>
      <pubDate>Sun, 24 Mar 2024 12:38:16 +0100</pubDate>
      <guid>http://localhost:1313/posts/robustai_regmixup/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;en&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;&lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;title&gt;Styled Table&lt;/title&gt;&#xD;&#xA;&lt;style&gt;&#xD;&#xA;    table {&#xD;&#xA;        border-collapse: collapse;&#xD;&#xA;        width: 100%;&#xD;&#xA;    }&#xD;&#xA;    th, td {&#xD;&#xA;        padding: 8px;&#xD;&#xA;        text-align: center;&#xD;&#xA;        border-bottom: 1px solid #ddd;&#xD;&#xA;    }&#xD;&#xA;    th {&#xD;&#xA;        background-color: #f2f2f2;&#xD;&#xA;    }&#xD;&#xA;    tr:hover {&#xD;&#xA;        background-color: #f5f5f5;&#xD;&#xA;    }&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;/html&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;RegMixup : Regularizer for robust AI&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Improve accuracy and Out-of-Distribution Robustness&lt;h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: Marius Ortega, Ly An CHHAY &lt;br /&gt;&#xD;&#xA;Paper : &lt;a href=&#34;https://arxiv.org/abs/2206.14502&#34;&gt;RegMixup&lt;/a&gt;  by Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Prerequisites&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.1&#34;&gt;Empirical Risk Minimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.2&#34;&gt;Vicinal Risk Minimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.3&#34;&gt;Mixup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;RegMixup in theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;RegMixup in practice &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0.0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;In this blog post, we will present the paper &amp;ldquo;RegMixup: Regularizer for robust AI&amp;rdquo; by Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania. This paper introduces a new regularizer called RegMixup, which is designed to improve the accuracy and out-of-distribution robustness of deep neural networks. The authors show that RegMixup can be used to improve the performance of state-of-the-art models on various datasets, including CIFAR-10, CIFAR-100, and ImageNet. The paper also provides an extensive empirical evaluation of RegMixup, demonstrating its effectiveness in improving the robustness of deep neural networks to out-of-distribution samples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints</title>
      <link>http://localhost:1313/posts/lambert-davy/</link>
      <pubDate>Sat, 23 Mar 2024 19:39:13 +0100</pubDate>
      <guid>http://localhost:1313/posts/lambert-davy/</guid>
      <description>&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: Godefroy LAMBERT and Louise DAVY&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Definitions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;AUC-based fairness constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;ROC-based fairness constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints, published by R. Vogel et al. in 2021 and available &lt;a href=&#34;http://proceedings.mlr.press/v130/vogel21a/vogel21a-supp.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;section-1&#34;&gt;&lt;h1 style=&#34;font-size: 24px; text-decoration: underline;&#34;&gt;Introduction&lt;/h1&gt;&lt;/h1&gt;&#xA;&lt;p&gt;With recent advances in machine learning, applications are becoming increasingly numerous and the expectations are high. Those applications will only be able to be deployed if some important issues are addressed such as bias. There are famous datasets known for containing variables that induce a lot of bias such as Compas with racial bias and gender bias in the Adult dataset. To avoid those biases, new algorithms were created to provide more fairness in the prediction by using diverse methods.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Label-Free Explainability</title>
      <link>http://localhost:1313/posts/label-free-explainability/</link>
      <pubDate>Sun, 17 Mar 2024 15:31:34 +0100</pubDate>
      <guid>http://localhost:1313/posts/label-free-explainability/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Label-Free Explainability for Unsupervised Models&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: &lt;a href=&#34;https://github.com/Valentinahxu&#34;&gt;Valentina Hu &lt;/a&gt; and  &lt;a href=&#34;https://github.com/selmazrg&#34;&gt; Selma Zarga&lt;/a&gt;&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Incentives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Feature Importance &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Example Importance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Experiment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Label-Free Explainability for Unsupervised Models, published by J. Crabbé et al. in 2022 and available &lt;a href=&#34;https://proceedings.mlr.press/v162/crabbe22a/crabbe22a.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Why do we need explainability ?&lt;/h2&gt;&#xA;&lt;p&gt;Machine learning models are becoming increasingly capable of making advanced predictions. While models like linear regression are relatively easy to understand and explain, more complex models, often called &lt;strong&gt;&amp;ldquo;black boxes&amp;rdquo;&lt;/strong&gt; due to their complexity, present challenges in explaining how they make predictions. These models can be problematic in highstakes applications such as healthcare, finance, and justice, where it&amp;rsquo;s crucial to justify decision-making. Additionally, in case of errors, it&amp;rsquo;s important to understand the origin in order to address and correct them.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Adversarially Reweighted Learning</title>
      <link>http://localhost:1313/posts/adversarially_reweighted_learning/</link>
      <pubDate>Mon, 04 Mar 2024 18:35:12 +0100</pubDate>
      <guid>http://localhost:1313/posts/adversarially_reweighted_learning/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Fairness without Demographics through Adversarially Reweighted Learning&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Authors: Pierre Fihey &amp; Guerlain Messin&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Fairness issues in ML and AI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;The privacy of demographic’s data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;The Adversarial Reweighted Learning Model&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;An Hypothesis: Protected Groups are Correlated with Both Features and Labels&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Computational identifiability of protected groups&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;The Rawlsian Max-Min Fairness principle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;The ARL objective&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;The Model Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-8&#34;&gt;Results analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-9&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Fairness without Demographics through Adversarially Reweighted Learning, published by P. Lahoti et al. in 2020 and available &lt;a href=&#34;https://dl.acm.org/doi/abs/10.5555/3495724.3495786&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Packed Ensembles</title>
      <link>http://localhost:1313/posts/packed-ensembles/</link>
      <pubDate>Tue, 27 Feb 2024 15:05:20 +0100</pubDate>
      <guid>http://localhost:1313/posts/packed-ensembles/</guid>
      <description>&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;div style=&#34;text-align:center;&#34;&gt;&#xD;&#xA;This is a blog post about the paper Packed-Ensembles for Efficient Uncertainty Estimation, published by O. Laurent et al. in 2023 and available [here](https://openreview.net/pdf?id=XXTyv1zD9zD).&#xD;&#xA;&lt;h3 id=&#34;authors-cynthia-obeid-and-elie-nakad&#34;&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Cynthia Obeid and Elie Nakad&lt;/h3&gt;&#xA;&lt;h1&gt;Introduction&lt;/h1&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;The document &#34;Packed-Ensembles for Efficient Uncertainty Estimation&#34; introduces a novel framework for designing and training compact, structured ensembles of neural networks, termed Packed-Ensembles (PE). It addresses the limitations of Deep Ensembles (DE) in terms of computational efficiency and hardware constraints by leveraging grouped convolutions. This technique allows for parallelizing the ensemble into a single shared backbone, improving training and inference speeds within the memory limits of standard neural networks. The paper demonstrates through extensive experiments that PEs maintain the beneficial properties of DEs, such as diversity and robustness to distribution shift, while achieving comparable accuracy, calibration, and out-of-distribution detection capabilities. The work includes implementation details, experimental results on CIFAR-10/100 and ImageNet datasets and comparisons with existing approaches. It concludes with insights on the reproducibility of results and the potential ethical considerations of deploying such models in safety-critical systems.&#xD;&#xA;&lt;div style=&#34;text-align:center;&#34;&gt;&#xD;&#xA;&lt;h1&gt;Presentation of the model&lt;/h1&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Packed-Ensembles&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Framework to Learn with Interpretation</title>
      <link>http://localhost:1313/posts/a-framework-to-learn-with-interpretation/</link>
      <pubDate>Tue, 13 Feb 2024 16:56:04 +0100</pubDate>
      <guid>http://localhost:1313/posts/a-framework-to-learn-with-interpretation/</guid>
      <description>&lt;hr&gt;&lt;/hr&gt;&#xD;&#xA;&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&lt;p&gt;code.has-jax {font:&#xA;inherit;&#xA;font-size:&#xA;100%;&#xA;background:&#xA;inherit;&#xA;border:&#xA;inherit;}&lt;/p&gt;&#xA;&lt;p&gt;&lt;/style&gt;&lt;/p&gt;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;A Framework to Learn with Interpretation&lt;/h1&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Authors: Maroun ABOU BOUTROS, Mohamad EL OSMAN&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Article: &lt;a href=&#34;https://arxiv.org/abs/2010.09345&#34;&gt;A Framework to Learn with Interpretation&lt;/a&gt; by Jayneel Parekh, Pavlo Mozharovskyi and Florence d’Alché-Buc&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>NTK-SAP: IMPROVING NEURAL NETWORK PRUNING BY ALIGNING TRAINING DYNAMICS</title>
      <link>http://localhost:1313/posts/ntk-sap/</link>
      <pubDate>Wed, 07 Feb 2024 16:07:10 +0100</pubDate>
      <guid>http://localhost:1313/posts/ntk-sap/</guid>
      <description>&lt;p&gt;This is a blog post about the paper NTK-SAP: Improving neural network pruning by aligning training dynamics, published by Y. Wang et al. in 2023 and available &lt;a href=&#34;https://openreview.net/pdf?id=-5EWhW_4qWP&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Introduction:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In a world increasingly driven by demand for data and computational resources, the narrative of artificial intelligence has been one of abundance: more data, more power, more precision. Yet, nestled within this grand tale, lies a quieter narrative - one that champions the concept of achieving more with less—Frugal AI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Do Perceptually Aligned Gradients imply Robustness?</title>
      <link>http://localhost:1313/posts/robustness-and-pag-the-converse/</link>
      <pubDate>Wed, 07 Feb 2024 16:06:43 +0100</pubDate>
      <guid>http://localhost:1313/posts/robustness-and-pag-the-converse/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Robustness and Perceptually Aligned Gradients : does the converse stand ?&lt;/h1&gt;&#xD;&#xA;&lt;h3 style=&#34;font-size: 24px;&#34;&gt;Author: Yohann Zerbib&lt;/h3&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Adversarial Attacks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Perceptually Aligned Gradients&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Experiment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;To go further&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Do Perceptually Aligned Gradients Imply Robustness?, published by R. Ganz et al. in 2023 and available &lt;a href=&#34;https://openreview.net/pdf?id=W6topEXC2-v&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>To update or not to update? Neurons at equilibrium in deep models</title>
      <link>http://localhost:1313/posts/neq/</link>
      <pubDate>Wed, 07 Feb 2024 15:55:14 +0100</pubDate>
      <guid>http://localhost:1313/posts/neq/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;To update or not to update? Neurons at equilibrium in deep models&#xD;&#xA;&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Alexis WINTER Augustin CREUSILLET&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-content&#34;&gt;Table of content&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;NEq&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper To update or not to update? Neurons at equilibrium in deep models, published by A. Bgragagnolo et al. in 2022 and available [here]https://proceedings.neurips.cc/paper_files/paper/2022/file/8b2fc235787852ead92da2268cd9e90c-Paper-Conference.pdf).&lt;/p&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;&#xA;&lt;p&gt;Recent advances in &lt;strong&gt;deep learning&lt;/strong&gt; have undeniably propelled the field to unprecedented heights, revolutionizing various domains from computer vision to natural language processing. However, these strides forward have not come without a significant toll on computational resources. As models grow increasingly complex, the demand for &lt;strong&gt;computational power&lt;/strong&gt; has surged exponentially. One of the most expensive tasks in deep learning is undoubtedly the training of models. This process entails iteratively adjusting millions or even billions of parameters to minimize a predefined loss function, requiring extensive computational power and time-intensive operations. This process poses challenges in terms of both &lt;strong&gt;affordability and environmental sustainability&lt;/strong&gt;, highlighting the need for innovative solutions to make deep learning more efficient and accessible in the face of escalating computational demands.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimal Transport Based Adversarial Patch Attacks</title>
      <link>http://localhost:1313/posts/optimal_transport_based_adversarial_patch/</link>
      <pubDate>Sat, 03 Feb 2024 22:22:36 +0100</pubDate>
      <guid>http://localhost:1313/posts/optimal_transport_based_adversarial_patch/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 id=&#34;authors&#34;&gt;Authors:&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Mohammed Jawhar&lt;/li&gt;&#xA;&lt;li&gt;Aymane Rahmoune&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;paper--optimal-transport-based-adversarial-based-patch-to-leverage-large-scale-attack-transferabilityhttpsopenreviewnetforumidnzp10evtkv&#34;&gt;Paper : &lt;a href=&#34;https://openreview.net/forum?id=nZP10evtkV&#34;&gt;Optimal Transport Based Adversarial Based Patch To Leverage Large Scale Attack Transferability&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;h1 id=&#34;table-of-contents-&#34;&gt;Table of contents :&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Understanding Adversarial Patch Attacks&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-11&#34;&gt;Decision boundary based&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-12&#34;&gt;Feature point based&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-13&#34;&gt;Distribution based&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Transferability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Optimal Transport&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Experiments&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-41&#34;&gt;Experimental Setup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-42&#34;&gt;Results and Findings&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-421&#34;&gt;Digital Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-422&#34;&gt;Hybrid Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-423&#34;&gt;Physical Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Imagine you&amp;rsquo;re showing a picture to a friend, asking them to guess who&amp;rsquo;s in it, then sticking a tiny, almost invisible sticker on that photo. For some reason, this sticker makes your friend completely unable to recognize who&amp;rsquo;s in the picture. This might sound like magic, but something similar can happen with Computer Vision models designed to capture an image content, either through a classification, a segmentation or even a generation task. These AI programs can be vulnerable to such tricks, that we call technically, Adversarial Patch Attacks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Statistical Minimax Rates Under Privacy</title>
      <link>http://localhost:1313/posts/statistical_minimax_rates_under_privacy/</link>
      <pubDate>Wed, 31 Jan 2024 17:22:02 +0100</pubDate>
      <guid>http://localhost:1313/posts/statistical_minimax_rates_under_privacy/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Estimating Privacy in Data Science: A Comprehensive Guide&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Antoine Klein &lt;a href=&#34;https://github.com/AntoineTSP&#34;&gt;Github Link&lt;/a&gt;&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Incentives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;The case of multinomial estimation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;The case of density estimation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Experiment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-8&#34;&gt;Quizz&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Why do we care about privacy ?&lt;/h2&gt;&#xA;&lt;p&gt;Imagine, you&amp;rsquo;re quietly at home when the doorbell rings. You open the door and a government official appears: population census. Even though he shows you his official badge and you&amp;rsquo;d like to help him in the public interest, you find it hard to answer his questions as you go along. Indeed, the first questions about the date of your move are easy and public. On the other hand, when he asks about the number of children, marital status or your salary and what you do with it, you &lt;em&gt;struggle&lt;/em&gt;. Not because you don&amp;rsquo;t know the answer, but because you&amp;rsquo;re faced with an &lt;strong&gt;ethical dilemma&lt;/strong&gt;: transparency towards the state versus protection of personal data.&lt;br&gt;&#xA;$$\text{In short, transparency goes against your privacy. }$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Measuring the Transferability of Pre-trained Models: a link with Neural Collapse Distances on Target Datasets</title>
      <link>http://localhost:1313/posts/transferability/</link>
      <pubDate>Mon, 08 Jan 2024 11:26:03 +0100</pubDate>
      <guid>http://localhost:1313/posts/transferability/</guid>
      <description>&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt; : Marion Chadal and Julie Massé&lt;/p&gt;&#xA;&lt;p&gt;This blog post discusses the paper &amp;ldquo;How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability&amp;rdquo; &lt;a href=&#34;#ref1&#34;&gt;[1]&lt;/a&gt;. It provides an explanation of it so that you can understand the usefulness of measuring transferability, and a reproduction of the authors&amp;rsquo; experiment so that you can better visualize their methodology.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Some additional informations about this course.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Florence d&amp;rsquo;Alché-Buc&lt;/strong&gt; is a full professor at Institut Polytechnique de Paris, Télécom Pari in Statistical Learning. She is the holder of the &amp;ldquo;Data Science and Artificial Intelligence for Digitalized Industry and Services&amp;rdquo; chair at Télécom Paris, and is mainly interested in learning from &lt;em&gt;complex&lt;/em&gt; data, in particular the supervised prediction of graphs, functions and spatio-temporal signals, exploiting the structure and geometry of these objects in regularization and cost functions. More recently, she has been working on the interpretability and robustness of predictive models. &lt;a href=&#34;https://perso.telecom-paristech.fr/fdalche/&#34;&gt;Link to personal webpage&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Articles</title>
      <link>http://localhost:1313/articles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/</guid>
      <description>&lt;p&gt;Hereafter you can find the list of articles proposed for this class and the link to the pdfs.&lt;/p&gt;&#xA;&lt;p&gt;Please add your name in the following &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1raZrD6JZQzjE0wmJbP4iM5-4yt9rAkJIFOqgj1q-JxU/edit?usp=sharing&#34;&gt;file&lt;/a&gt; to pick an article and enter your &lt;strong&gt;github username&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note 1&lt;/strong&gt;: this work can be done in teams (&lt;span style=&#34;text-decoration:underline&#34;&gt;maximum 2 students&lt;/span&gt;).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note 2&lt;/strong&gt;: an article can only be chosen by &lt;span style=&#34;text-decoration:underline&#34;&gt;1 team&lt;/span&gt;.&lt;/p&gt;&#xA;&lt;hr/&gt;&#xD;&#xA;&lt;h2 id=&#34;interpretable-ai&#34;&gt;Interpretable AI&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Jayneel Parekh, Pavlo Mozharovskyi, Florence d&amp;rsquo;Alché-Buc, A Framework to Learn with Interpretation. Advances in Neural Information Processing Systems (2021)&lt;a href=&#34;https://proceedings.neurips.cc/paper/2021/file/cbb6a3b884f4f88b3a8e3d44c636cbd8-Paper.pdf&#34;&gt;[link to pdf]&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Jonathan Crabbé, Mihaela van der Schaar, Label-Free Explainability for Unsupervised Models, International Conference on Machine Learning (2022) &lt;a href=&#34;https://proceedings.mlr.press/v162/crabbe22a.html&#34;&gt;[link to pdf]&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Hamilton, M., Lundberg, S., Fu, S., Zhang, L., &amp;amp; Freeman, W. T., Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning. In International Conference on Learning Representations (2021)  &lt;a href=&#34;https://openreview.net/pdf?id=TqNsv1TuCX9&#34;&gt;[link to pdf]&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;frugal-ai&#34;&gt;Frugal AI&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Wang, Zijian, et al. &lt;em&gt;How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability.&lt;/em&gt; Proceedings of the IEEE/CVF International Conference on Computer Vision. (2023). &lt;a href=&#34;https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.pdf&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Wang, Yite, Dawei Li, and Ruoyu Sun. &lt;em&gt;NTK-SAP: Improving neural network pruning by aligning training dynamics.&lt;/em&gt; International Conference on Learning Representations (2023). &lt;a href=&#34;https://arxiv.org/abs/2304.02840&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Bragagnolo, Andrea, Enzo Tartaglione, and Marco Grangetto. &lt;em&gt;To update or not to update? Neurons at equilibrium in deep models.&lt;/em&gt; Advances in Neural Information Processing Systems (2022). &lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2022/file/8b2fc235787852ead92da2268cd9e90c-Paper-Conference.pdf&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Yang, Adam X and Robeyns, Maxime and Wang, Xi and Aitchison, Laurence, Bayesian low-rank adaptation for large language models, International Conference on Learning Representations (2024) &lt;a href=&#34;https://openreview.net/pdf?id=FJiUyzOF1m&#34;&gt;[link to pdf]&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;robust-ai&#34;&gt;Robust AI&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Olivier Laurent, Adrien Lafage, Enzo Tartaglione, Geoffrey Daniel, Jean-Marc Martinez, Andrei Bursuc, Gianni Franchi. &lt;em&gt;Packed-Ensembles for Efficient Uncertainty Estimation&lt;/em&gt;,  International Conference on Learning Representations (2023). &lt;a href=&#34;https://openreview.net/pdf?id=XXTyv1zD9zD&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania, &lt;em&gt;RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and Out Distribution Robustness&lt;/em&gt;, Advances in Neural Information Processing Systems (2022).&lt;a href=&#34;https://openreview.net/pdf?id=5j6fWcPccO&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Roy Ganz, Bahjat Kawar, Michael Elad, &lt;em&gt;Do Perceptually Aligned Gradients Imply Robustness?&lt;/em&gt;, International Conference on Machine Learning (2023). &lt;a href=&#34;http://proceedings.mlr.press/v202/ganz23a/ganz23a.pdf&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Anonymous, Optimal Transport Based Adversarial Patch to Leverage Large Scale Attack Transferability, International Conference in Representation Learning, to appear 2024 &lt;a href=&#34;https://openreview.net/forum?id=nZP10evtkV&#34;&gt;[link to pdf]&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;fairness&#34;&gt;Fairness&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;R. Vogel, A. Bellet and S. Clémençon. &lt;em&gt;Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints.&lt;/em&gt; International Conference on Artificial Intelligence and Statistics (AISTATS), 2021. &lt;a href=&#34;http://researchers.lille.inria.fr/abellet/papers/aistats21.pdf&#34;&gt;[link to pdf]&lt;/a&gt;, &lt;a href=&#34;http://researchers.lille.inria.fr/abellet/papers/aistats21_supp.pdf&#34;&gt;[link to supplementary]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Preethi Lahoti et al. &lt;em&gt;Fairness without Demographics through Adversarially Reweighted Learning&lt;/em&gt;.  Advances in Neural Information Processing Systems (2020). &lt;a href=&#34;https://proceedings.neurips.cc/paper/2020/file/07fc15c9d169ee48573edd749d25945d-Paper.pdf&#34;&gt;[link to pdf]&lt;/a&gt;, &lt;a href=&#34;https://github.com/lucweytingh/ARL-UvA&#34;&gt;[link to github]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;privacy&#34;&gt;Privacy&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;John C. Duchi, Michael I. Jordan, and Martin Wainwright.  Privacy Aware Learning. Advances in Neural Information Processing Systems (2012). &lt;a href=&#34;https://web.stanford.edu/~jduchi/projects/DuchiJoWa12.html&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;John C. Duchi, Michael I. Jordan, and Martin Wainwright.  Local Privacy and Statistical Minimax Rates. FOCS (2013). &lt;a href=&#34;https://arxiv.org/abs/1302.3203&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;John C. Duchi, Michael I. Jordan, and Martin Wainwright. Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation. Advances in Neural Information Processing Systems (2013). &lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2013/file/5807a685d1a9ab3b599035bc566ce2b9-Paper.pdf&#34;&gt;[link to pdf]&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Tutorial</title>
      <link>http://localhost:1313/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/tutorial/</guid>
      <description>&lt;p&gt;How to create and publish your blogpost ?&lt;/p&gt;&#xA;&lt;hr/&gt;&#xD;&#xA;&lt;p&gt;The blogpost builds upon &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and &lt;a href=&#34;https://www.markdownguide.org/&#34;&gt;Markdown&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;For markdown you can easily find a cheat sheet &lt;a href=&#34;https://www.markdownguide.org/cheat-sheet/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;ol start=&#34;0&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Setup: you need to have a GitHub Account, a terminal and a text editor of your choice (e.g.VSCode, nano, gedit)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Install Hugo on your laptop. Hugo is available for all operating systems. You can find the installation guide &lt;a href=&#34;https://gohugo.io/installation/&#34;&gt;here&lt;/a&gt;. Be careful, you need at least Hugo version 0.120 otherwise, this will not work!&#xA;To verify your version&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
